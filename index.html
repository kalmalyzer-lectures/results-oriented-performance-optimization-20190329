
<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

# Results-Oriented Performance Optimization

Mikael Kalms

CTO, Fall Damage

mikael@kalms.org

---

# Purpose of this session

We will practice optimization in a structured manner.

---

# What is optimization?

Optimization is the process of improving something.

How do you tell if something has improved?

It helps to have a **goal** to compare against.

It helps to have a **metric**, to measure progress toward the goal.

---

# Examples of goals + metrics

Any level in the game should load in <30 seconds on PS4.

The particle system must never use more than 300MB RAM.

The fog and mist should take <1ms but still look decent.

The game should be <1GB on-disk, decompression can use max 10MB temp RAM, load times can increase with <20%.

---

# Optimization is a tradeoff

Sometimes, improving one aspect helps in other aspects as well.

Sometimes, improving one aspect worsens another aspect.

---

# The "engineering definition" of optimization

"Make changes to a system...

...to reach an optimal balance between conflicting parameters...

...while observing hard constraints"

---

# What is a metric?

It is something that you can measure. Examples:

* load time for a level
* max memory usage during a play session
* Average packet transfer latency between two machines
* user enjoyment (1 = low, 5 = high) when playing through a level

---

# How to perform software optimization

Pick a goal.

Pick a metric that is relevant.

Change the code.

Measure how the metric has changed.

Repeat.

---

# Tips when establishing goals

Make napkin estimations for what a reasonable goal would be.

Work backwards from physical constraints.
- What is the RAM throughput of your system?
- How many instructions/second can the CPU in your system process?
- What is the bandwidth of the network interface in your machine?
- What is the read throughput of a DVD drive?

---

# Tips when measuring metrics

If you cannot measure the metric directly, pick a metric that you can measure, that correlates positively to the one you want to optimize.

When you measure it, write it down. _Always._

If you measure the same thing many times, automate measurement + logging.

---

# This dilemma always comes up

Change algorithm, or improve the existing implementation?

---

# Performance Profiling Tools

* Task Manager
* ETW
* Brofiler / Orbit Profiler
* Very Sleepy
* VTune
* Visual Studio's profiler
* Unity/Unreal's built-in profilers
* Console specific profilers
* Use std::chrono yourself

---

# Memory profiling tools

* Task Manager
* ETW
* mtuner
* Visual Studio's profiler
* Unity/Unreal's built-in profilers
* Console specific profilers
* Hook malloc / global new yourself

---

# Network profiling tools

* Task Manager
* ETW
* Wireshark
* Write your own

---

# Disk profiling tools

* Task Manager
* ETW
* Write your own



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>